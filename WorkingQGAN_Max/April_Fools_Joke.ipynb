{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrwEnBIarR8X"
      },
      "source": [
        "# Imports\n",
        "## Note: If making major changes, try on a copy of this notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwTRnTcOvf8T",
        "outputId": "3cb1609f-6d07-4caa-dcd0-5c3fe09310fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.0.4-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 17.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip3 install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_ViiXD4Pnro",
        "outputId": "18343f90-ea6f-4eb0-cd3d-8cd6747598f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.22.2-py3-none-any.whl (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.8/880.8 KB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pennylane-lightning>=0.22\n",
            "  Downloading PennyLane_Lightning-0.22.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.21.5)\n",
            "Collecting autoray\n",
            "  Downloading autoray-0.2.5-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.7/dist-packages (from pennylane) (4.2.4)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.3)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.4.1)\n",
            "Collecting semantic-version==2.6\n",
            "  Downloading semantic_version-2.6.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pennylane) (2.6.3)\n",
            "Collecting retworkx\n",
            "  Downloading retworkx-0.11.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.1/108.1 KB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd->pennylane) (0.16.0)\n",
            "Installing collected packages: semantic-version, ninja, toml, retworkx, autoray, pennylane-lightning, pennylane\n",
            "Successfully installed autoray-0.2.5 ninja-1.10.2.3 pennylane-0.22.2 pennylane-lightning-0.22.1 retworkx-0.11.0 semantic-version-2.6.0 toml-0.10.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip3 install pennylane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D6-GrrkpP_1Q"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import pennylane as qml\n",
        "\n",
        "# Pytorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3uaAKoLX0pF",
        "outputId": "80cdc26c-95f3-4706-bc2d-d43f19531e8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-0.35.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting qiskit-terra==0.20.0\n",
            "  Downloading qiskit_terra-0.20.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qiskit-aer==0.10.3\n",
            "  Downloading qiskit_aer-0.10.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (18.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qiskit-ibmq-provider==0.18.3\n",
            "  Downloading qiskit_ibmq_provider-0.18.3-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.1/238.1 KB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qiskit-ignis==0.7.0\n",
            "  Downloading qiskit_ignis-0.7.0-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.9/200.9 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-aer==0.10.3->qiskit) (1.21.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-aer==0.10.3->qiskit) (1.4.1)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.18.3->qiskit) (1.24.3)\n",
            "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.18.3->qiskit) (2.23.0)\n",
            "Collecting requests-ntlm>=1.1.0\n",
            "  Downloading requests_ntlm-1.1.0-py2.py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.18.3->qiskit) (2.8.2)\n",
            "Collecting websocket-client>=1.0.1\n",
            "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-ignis==0.7.0->qiskit) (57.4.0)\n",
            "Requirement already satisfied: retworkx>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-ignis==0.7.0->qiskit) (0.11.0)\n",
            "Collecting symengine>=0.9\n",
            "  Downloading symengine-0.9.2-cp37-cp37m-manylinux2010_x86_64.whl (37.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.5/37.5 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=1.0\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tweedledum<2.0,>=1.1\n",
            "  Downloading tweedledum-1.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (943 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m943.8/943.8 KB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-constraint>=1.4\n",
            "  Downloading python-constraint-1.4.0.tar.bz2 (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting stevedore>=3.0.0\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dill>=0.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.20.0->qiskit) (0.3.4)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.20.0->qiskit) (5.4.8)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.20.0->qiskit) (1.7.1)\n",
            "Collecting ply>=3.10\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.8.0->qiskit-ibmq-provider==0.18.3->qiskit) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.18.3->qiskit) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.18.3->qiskit) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.18.3->qiskit) (2021.10.8)\n",
            "Collecting ntlm-auth>=1.0.2\n",
            "  Downloading ntlm_auth-1.5.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting cryptography>=1.3\n",
            "  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.0/113.0 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from stevedore>=3.0.0->qiskit-terra==0.20.0->qiskit) (4.11.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.3->qiskit-terra==0.20.0->qiskit) (1.2.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.18.3->qiskit) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.7.0->stevedore>=3.0.0->qiskit-terra==0.20.0->qiskit) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.7.0->stevedore>=3.0.0->qiskit-terra==0.20.0->qiskit) (3.7.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.18.3->qiskit) (2.21)\n",
            "Building wheels for collected packages: qiskit, python-constraint\n",
            "  Building wheel for qiskit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qiskit: filename=qiskit-0.35.0-py3-none-any.whl size=11839 sha256=2c4dcea2bf5432e501b5994779066ef4855c7e13e0c0d173299c95de413ed3a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/0a/42/93e5cc11795fb0a85fcf6686eac2791def0c9a1cad0a774045\n",
            "  Building wheel for python-constraint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-constraint: filename=python_constraint-1.4.0-py2.py3-none-any.whl size=24081 sha256=54ccca2c96b228914a0fae233080f2043cd8a6036d5bffedead304190ba52362\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/27/db/1222c80eb1e431f3d2199c12569cb1cac60f562a451fe30479\n",
            "Successfully built qiskit python-constraint\n",
            "Installing collected packages: python-constraint, ply, websocket-client, tweedledum, symengine, scipy, pbr, ntlm-auth, stevedore, cryptography, requests-ntlm, qiskit-terra, qiskit-ignis, qiskit-ibmq-provider, qiskit-aer, qiskit\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cryptography-36.0.2 ntlm-auth-1.5.0 pbr-5.8.1 ply-3.11 python-constraint-1.4.0 qiskit-0.35.0 qiskit-aer-0.10.3 qiskit-ibmq-provider-0.18.3 qiskit-ignis-0.7.0 qiskit-terra-0.20.0 requests-ntlm-1.1.0 scipy-1.7.3 stevedore-3.5.0 symengine-0.9.2 tweedledum-1.1.1 websocket-client-1.3.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting pennylane-qiskit\n",
            "  Downloading PennyLane_qiskit-0.22.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: pennylane>=0.22 in /usr/local/lib/python3.7/dist-packages (from pennylane-qiskit) (0.22.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from pennylane-qiskit) (2.6.3)\n",
            "Collecting mthree>=0.17\n",
            "  Downloading mthree-0.22.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: qiskit>=0.25 in /usr/local/lib/python3.7/dist-packages (from pennylane-qiskit) (0.35.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pennylane-qiskit) (1.21.5)\n",
            "Requirement already satisfied: qiskit-terra>=0.18 in /usr/local/lib/python3.7/dist-packages (from mthree>=0.17->pennylane-qiskit) (0.20.0)\n",
            "Requirement already satisfied: cython>=0.29 in /usr/local/lib/python3.7/dist-packages (from mthree>=0.17->pennylane-qiskit) (0.29.28)\n",
            "Requirement already satisfied: qiskit-ibmq-provider>=0.15 in /usr/local/lib/python3.7/dist-packages (from mthree>=0.17->pennylane-qiskit) (0.18.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from mthree>=0.17->pennylane-qiskit) (5.4.8)\n",
            "Collecting orjson>=3.0.0\n",
            "  Downloading orjson-3.6.7-cp37-cp37m-manylinux_2_24_x86_64.whl (255 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.4/255.4 KB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.7/dist-packages (from mthree>=0.17->pennylane-qiskit) (1.7.3)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.7/dist-packages (from pennylane>=0.22->pennylane-qiskit) (1.3)\n",
            "Requirement already satisfied: autoray in /usr/local/lib/python3.7/dist-packages (from pennylane>=0.22->pennylane-qiskit) (0.2.5)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pennylane>=0.22->pennylane-qiskit) (0.10.2)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.7/dist-packages (from pennylane>=0.22->pennylane-qiskit) (4.2.4)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pennylane>=0.22->pennylane-qiskit) (1.4.4)\n",
            "Requirement already satisfied: pennylane-lightning>=0.22 in /usr/local/lib/python3.7/dist-packages (from pennylane>=0.22->pennylane-qiskit) (0.22.1)\n",
            "Requirement already satisfied: retworkx in /usr/local/lib/python3.7/dist-packages (from pennylane>=0.22->pennylane-qiskit) (0.11.0)\n",
            "Requirement already satisfied: semantic-version==2.6 in /usr/local/lib/python3.7/dist-packages (from pennylane>=0.22->pennylane-qiskit) (2.6.0)\n",
            "Requirement already satisfied: qiskit-ignis==0.7.0 in /usr/local/lib/python3.7/dist-packages (from qiskit>=0.25->pennylane-qiskit) (0.7.0)\n",
            "Requirement already satisfied: qiskit-aer==0.10.3 in /usr/local/lib/python3.7/dist-packages (from qiskit>=0.25->pennylane-qiskit) (0.10.3)\n",
            "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (2.8.2)\n",
            "Requirement already satisfied: websocket-client>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (1.3.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (1.24.3)\n",
            "Requirement already satisfied: requests-ntlm>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (1.1.0)\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-ignis==0.7.0->qiskit>=0.25->pennylane-qiskit) (57.4.0)\n",
            "Requirement already satisfied: ply>=3.10 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (3.11)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (1.7.1)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (3.5.0)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (0.3.4)\n",
            "Requirement already satisfied: python-constraint>=1.4 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (1.4.0)\n",
            "Requirement already satisfied: tweedledum<2.0,>=1.1 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (1.1.1)\n",
            "Requirement already satisfied: symengine>=0.9 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (0.9.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.7/dist-packages (from pennylane-lightning>=0.22->pennylane>=0.22->pennylane-qiskit) (1.10.2.3)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd->pennylane>=0.22->pennylane-qiskit) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.8.0->qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (3.0.4)\n",
            "Requirement already satisfied: cryptography>=1.3 in /usr/local/lib/python3.7/dist-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (36.0.2)\n",
            "Requirement already satisfied: ntlm-auth>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (1.5.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from stevedore>=3.0.0->qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (5.8.1)\n",
            "Requirement already satisfied: importlib-metadata>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from stevedore>=3.0.0->qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (4.11.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.3->qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (1.2.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.7.0->stevedore>=3.0.0->qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.7.0->stevedore>=3.0.0->qiskit-terra>=0.18->mthree>=0.17->pennylane-qiskit) (3.7.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider>=0.15->mthree>=0.17->pennylane-qiskit) (2.21)\n",
            "Installing collected packages: orjson, mthree, pennylane-qiskit\n",
            "Successfully installed mthree-0.22.0 orjson-3.6.7 pennylane-qiskit-0.22.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip3 install qiskit\n",
        "!pip3 install pennylane-qiskit\n",
        "\n",
        "from qiskit import Aer\n",
        "import pennylane_qiskit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvnFPDmqrXOo"
      },
      "source": [
        "# Dataset Loader\n",
        "### Completed (working on V3)     \n",
        "@TODO: Gain ideas from MolGAN ✅  \n",
        "@FIXED: `process` function not returning anything  \n",
        "@UPDATE: Now loads all 11847 molecules into a giant array -> each array item contains details about one molecule  \n",
        "@FIXED: `__getitem__` method not working as intended  \n",
        "@UPDATE: each array item has the same size for generator (padded with dummy values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D01hEXJ0rBNR"
      },
      "outputs": [],
      "source": [
        "class MoleculesLoader(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_file: str, transform=None) -> None:\n",
        "        self.csv = csv_file\n",
        "        self.atom_dict = {\"H\" : 1, \"C\" : 2, \"O\" : 3, \"N\" : 4}\n",
        "        self.transform = transform\n",
        "        self.df = self.process()\n",
        "        self._normalize()\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx) -> list:\n",
        "        if torch.is_tensor(idx): idx = idx.tolist()\n",
        "        return self.df[idx]\n",
        "\n",
        "    def process(self) -> None:\n",
        "        tmp_df = self.csv #not actually csv file but array\n",
        "        df = [None] * len(tmp_df)\n",
        "        for i in range(len(tmp_df)):\n",
        "            mol_df = pd.read_csv(tmp_df[i])\n",
        "            #print(f\"mol_df={mol_df}\")\n",
        "            tmp_vec = [None] * len(mol_df)\n",
        "            for j in range(len(mol_df)):\n",
        "                data = mol_df.iloc[j]\n",
        "                atom, x, y, z = data[\"atom\"], data[\"x\"], data[\"y\"], data[\"z\"]\n",
        "                #print(f\"Atom={self.atom_dict[atom]}, x={x}, y={y}, z={z}.\")\n",
        "                tmp_vec[j] = (self.atom_dict[atom], x, y, z)\n",
        "            df[i] = tmp_vec\n",
        "        return df\n",
        "\n",
        "    def _normalize(self):\n",
        "        maxlen = max([len(x) for x in self.df])\n",
        "        self.size = maxlen\n",
        "        for i in range(len(self.df)):\n",
        "            while len(self.df[i]) != maxlen:\n",
        "                self.df[i].append([0, 0.0, 0.0, 0.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJjK-tq0hOmd",
        "outputId": "27f94e18-b9d0-47e5-8ade-a43823ff0c89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23\n"
          ]
        }
      ],
      "source": [
        "csv = [f\"/content/mol_xyz_{i}.csv\" for i in range(int(input()))] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fgeRhbKuj-Dq"
      },
      "outputs": [],
      "source": [
        "Loaded = MoleculesLoader(csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wwt1ephVlSfo",
        "outputId": "ae7b2e21-5111-4e05-8e48-6ddb381ea896"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "Loaded.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMeo8twZrh-3"
      },
      "source": [
        "# Generator\n",
        "## Optimized for generating molecules (random decimals)\n",
        "@Task Deadline: Wednesday  \n",
        "@UPDATE: Given current Generator problems probably going to take a *long* time.    \n",
        "@UPDATE: Fixed on 03/15/22    \n",
        "@NOTE: Do not use 32+ qubits (too much RAM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iJ8hXeO6P3SD"
      },
      "outputs": [],
      "source": [
        "n_qubits = 20  # Total number of qubits / N\n",
        "n_a_qubits = 1  # Number of ancillary qubits / N_A\n",
        "q_depth = 1  # Depth of the parameterised quantum circuit / D #try 1 for now\n",
        "\n",
        "#We dont need this line anymore\n",
        "#n_generators = 1  # Number of subgenerators for the patch method / N_G well obviously 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk1vWlruQBGU",
        "outputId": "6846fc36-676c-4b73-b6c7-a98cdf1a4040"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AerDevice device (wires=20, shots=1024) at 0x7f3f71a827d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
        "#dev = qml.device(\"qiskit.aer\", wires=n_qubits)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #NTS: use GPU runtime\n",
        "\n",
        "dev = qml.device('qiskit.aer', wires=n_qubits, shots=1024, backend='qasm_simulator')\n",
        "dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAp9ogpPj9TC",
        "outputId": "400999d7-12ac-472b-a03e-a467ef940370"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hovKh9GVuUCI"
      },
      "source": [
        "Uncomment the comments to add more complexity and/or parametrized gates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "frNn_PvqQE97"
      },
      "outputs": [],
      "source": [
        "@qml.qnode(dev, interface=\"torch\", diff_method=\"parameter-shift\")\n",
        "def quantum_circuit(noise, weights):\n",
        "    weights = weights.reshape(q_depth, n_qubits)\n",
        "    #Optional: superposition\n",
        "    for i in range(n_qubits):\n",
        "        qml.Hadamard(wires=i)\n",
        "        qml.CNOT(wires=[i, (i+1) % n_qubits])\n",
        "\n",
        "    # Initialise latent vectors using noise\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(noise[i], wires=i)\n",
        "\n",
        "    # Repeated layer\n",
        "    for i in range(q_depth):\n",
        "        # Parameterised layer\n",
        "        for y in range(n_qubits):\n",
        "            qml.RY(weights[i][y], wires=y)\n",
        "            #Optional: more parameters\n",
        "            #qml.RX(weights[i][y], wires=y)\n",
        "            #qml.RZ(weights[i][y], wires=y)\n",
        "\n",
        "        # Control Z gates\n",
        "        for y in range(n_qubits - 1):\n",
        "            qml.CZ(wires=[y, y + 1])\n",
        "\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YWwnUutuQpxj"
      },
      "outputs": [],
      "source": [
        "#returns a list of 1 and 0 based on probs\n",
        "def partial_measure(noise, weights):\n",
        "    probs = quantum_circuit(noise, weights)\n",
        "    bits = [\"0\" if x < 0 else \"1\" for x in probs]\n",
        "    return bits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "D8T4A6QYhtOL"
      },
      "outputs": [],
      "source": [
        "tmp_noise = torch.rand(n_qubits, device=device) * math.pi / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MHDoJ5Tahwuu"
      },
      "outputs": [],
      "source": [
        "sussy = nn.ParameterList([nn.Parameter(torch.rand(q_depth * n_qubits), requires_grad=True)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuOoyFkXiBhi",
        "outputId": "332faa70-8003-4f74-9bcb-5ba473b594df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0.6949, 0.2347, 0.4590, 0.2081, 0.0073, 0.8151, 0.6604, 0.6423, 0.0493,\n",
              "        0.4167, 0.3104, 0.7426, 0.9364, 0.5252, 0.5383, 0.7178, 0.9428, 0.2243,\n",
              "        0.6175, 0.7266], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "sussy[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_noise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blcPn0iMUOQi",
        "outputId": "89de60e3-db7b-4050-a98d-5c7b6154e7dd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0420, 0.7121, 1.1398, 0.0057, 0.5743, 0.4509, 0.0956, 1.3919, 0.7371,\n",
              "        0.2116, 1.0730, 0.5368, 0.1684, 1.0057, 0.7590, 0.0263, 0.0107, 0.0307,\n",
              "        1.5296, 1.2674])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jYmUMcqGiIjz"
      },
      "outputs": [],
      "source": [
        "bruh = partial_measure(tmp_noise, sussy[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "vNBlpFLckVkF",
        "outputId": "e44aefff-6e74-42d4-f824-74441eed2863"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10111010010111110010'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "''.join(bruh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW-fcnTLudmK"
      },
      "source": [
        "@TODO: ``forward()` function needs to be cmpletely modified to work for random noise input.  \n",
        "@UPDATE: Given this, it'll probably take at least 2 days (*expect Wednesday*) to complete but even then functionability not guaranteed    \n",
        "@UPDATE: Fixed on Tuesday"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "P9jWLTl2Qx1v"
      },
      "outputs": [],
      "source": [
        "class QuantumGenerator(nn.Module):\n",
        "    \"\"\"Quantum generator class\"\"\"\n",
        "\n",
        "    def __init__(self, q_delta=1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            n_generators (int): Number of sub-generators to be used in the patch method.\n",
        "            q_delta (float, optional): Spread of the random distribution for parameter initialisation.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.q_params = nn.ParameterList(\n",
        "            [\n",
        "                nn.Parameter(q_delta * torch.rand(q_depth * n_qubits), requires_grad=True)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        molecules = []\n",
        "        for params in self.q_params:\n",
        "            #for elem in x:\n",
        "            q_out = partial_measure(x, params) #q_out is a list of 1 and 0\n",
        "            bitstr = \"\".join(q_out)\n",
        "            molecules.append(bitstr)\n",
        "        return molecules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "B_Jdb0s2RjnE"
      },
      "outputs": [],
      "source": [
        "lrG = 0.3  # Learning rate for the generator\n",
        "lrD = 0.01  # Learning rate for the discriminator\n",
        "num_iter = 1  # Number of training iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "j8F014hpkfK-"
      },
      "outputs": [],
      "source": [
        "tmp_gen = QuantumGenerator().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NC-0_zqZkjXO"
      },
      "outputs": [],
      "source": [
        "tmp_out = tmp_gen.forward(tmp_noise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FepRMHX5kny0",
        "outputId": "d1f407aa-c7ce-46fa-c1b4-50aa75479701"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['01000010011111011101']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "tmp_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EiBZIlEnx7F"
      },
      "source": [
        "# Post Generator / Pre Discriminator Processing\n",
        "### Completed\n",
        "@Task Deadline: Monday ✅  \n",
        "@UPDATE: Wrapped in a class for better UX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "UQSx1YC1uXJY"
      },
      "outputs": [],
      "source": [
        "class Processing(object):\n",
        "    def __init__(self, noab: int=2, nocb: int=6) -> None:\n",
        "        self.pi = np.pi\n",
        "        self.atom_dict = {\"00\" : 1, \"01\" : 2, \"10\" : 3, \"11\" : 4}\n",
        "        self.num_of_atoms = 1\n",
        "        self.bits_per_atom = noab\n",
        "        self.bits_per_coord = nocb\n",
        "        self.sign_bit = 1\n",
        "        self.num_of_total_bits = self.num_of_atoms * (\n",
        "            self.bits_per_atom + 3 * (self.sign_bit + self.bits_per_coord)\n",
        "        )\n",
        "\n",
        "\n",
        "    def whichAtom(self, atom: str) -> str:\n",
        "        try: x = self.atom_dict[atom]\n",
        "        except KeyError: raise Exception(f\"Key: {atom} is not in atom_dict!\")\n",
        "        else: return x \n",
        "\n",
        "    def calcDistance(self, coord_dist, num_of_qubits: int, sign: bool) -> float:\n",
        "        distance = float(int(coord_dist) / pow(2, num_of_qubits-2))\n",
        "        return (distance * -1 if sign else distance)\n",
        "\n",
        "    def atomsAndCoordinates(self, generatedVector: str) -> list:\n",
        "        genVec = generatedVector\n",
        "        atomBS = genVec[0:self.bits_per_atom]\n",
        "        signx = (True if genVec[0] == \"1\" else False)\n",
        "        xcoord = genVec[self.bits_per_atom:self.bits_per_atom+self.bits_per_coord]\n",
        "        signy = (True if genVec[self.bits_per_atom+self.bits_per_coord] == \"1\" else False)\n",
        "        ycoord = genVec[1+self.bits_per_atom+self.bits_per_coord:1+self.bits_per_atom+self.bits_per_coord*2]\n",
        "        signz = (True if genVec[1+self.bits_per_atom+self.bits_per_coord*2] == \"1\" else False)\n",
        "        zcoord = genVec[2+self.bits_per_atom+self.bits_per_coord*2:]\n",
        "        atom = self.whichAtom(atomBS)\n",
        "        xdist = self.calcDistance(xcoord, self.bits_per_coord, signx)\n",
        "        ydist = self.calcDistance(ycoord, self.bits_per_coord, signy)\n",
        "        zdist = self.calcDistance(zcoord, self.bits_per_coord, signz)\n",
        "        return [atom, xdist, ydist, zdist]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "OIuCMQA9k27H"
      },
      "outputs": [],
      "source": [
        "PRO = Processing(nocb=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "kD1Z7ed7On1C"
      },
      "outputs": [],
      "source": [
        "tmp_pro = [PRO.atomsAndCoordinates(out) for out in tmp_out]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "t_RqhxTqOvgn"
      },
      "outputs": [],
      "source": [
        "tmp_pro = torch.tensor(tmp_pro)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se0ThbioPGfC",
        "outputId": "2e0874b9-7f36-4a81-8839-b0f6cbc68aae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.0000e+00,  1.2500e-01,  1.3888e+02, -1.3876e+03]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "tmp_pro"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PRO.num_of_total_bits == n_qubits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz3K5VabFIUD",
        "outputId": "509289bd-a1e4-451a-bdc1-5d56c7a6b0dd"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6mck8j8rcb0"
      },
      "source": [
        "# Discriminator\n",
        "### Optimized towards molecules instead of images\n",
        "@Task Deadline: **COMPLETED**  \n",
        "@TODO: Check how MolGAN people loaded the molecules ✅  \n",
        "@UPDATE: Added options to save and load model  \n",
        "@UPDATE: Changed model architecture  \n",
        "@FIXED: `TypeError: linear(): argument 'input' (position 1) must be Tensor, not list`   \n",
        "@PROBLEM: `torch.tensor()` doesn't work on lists with more than one `dtype`  \n",
        "@FIXED: ⬆️ use ASCII value of string `(dtype=int)`.  \n",
        "@UPDATE: Fixed issues with Doubles and Floats   \n",
        "@UPDATE: Add capabilities for dynamic-sized inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "v7VvDJqLuub2"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, data_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.data_shape = data_shape\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            #MORE RAM\n",
        "            #nn.Linear(int(np.prod(self.data_shape)), 262144),\n",
        "            #nn.LeakyReLU(0.2, inplace=True),\n",
        "            #nn.Linear(262144, 512),\n",
        "            #nn.LeakyReLU(0.2, inplace=True),\n",
        "            #nn.Linear(512, 1),\n",
        "\n",
        "            nn.Linear(4, int(np.prod(self.data_shape))),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(56, 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(8, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, mol):\n",
        "        #print(len(mol), len(mol[0]))\n",
        "        validity = self.model(mol.float())\n",
        "        return validity\n",
        "\n",
        "    def save(self, path):\n",
        "        save_dict = {\n",
        "            'model': self.model.state_dict(),\n",
        "            'data_shape': self.data_shape,\n",
        "        }\n",
        "        torch.save(save_dict, path)\n",
        "        return\n",
        "\n",
        "    @staticmethod\n",
        "    def load(path):\n",
        "        save_dict = torch.load(path)\n",
        "        D = Discriminator(save_dict['data_shape'])\n",
        "        D.model.load_state_dict(save_dict[\"model\"])\n",
        "\n",
        "        return D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1PeAN_nSmq3C"
      },
      "outputs": [],
      "source": [
        "D = Discriminator(data_shape=(Loaded.size, 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYE2-FIbmzu6",
        "outputId": "8bdb62af-2e1e-46bb-9f05-72c31f64f970"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=4, out_features=56, bias=True)\n",
              "  (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  (2): Linear(in_features=56, out_features=8, bias=True)\n",
              "  (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  (4): Linear(in_features=8, out_features=1, bias=True)\n",
              "  (5): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "D.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cS9QoujgP0cR"
      },
      "outputs": [],
      "source": [
        "ttsx = D.forward(torch.tensor(Loaded.df[0], dtype=torch.double, requires_grad=True)).view(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function"
      ],
      "metadata": {
        "id": "B3ITXaz7ZweF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MoleculeLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(MoleculeLoss, self).__init__()\n",
        "        self.actual_loss_func = nn.BCELoss()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1, device=None):\n",
        "        if not inputs.requires_grad: inputs.requires_grad = True\n",
        "        if not targets.requires_grad: targets.requires_grad = True\n",
        "        #supposedly Wasserstein loss\n",
        "        #inputs = #F. [function]\n",
        "        inputs = inputs.view(-1)\n",
        "        inputs = torch.tensor(list(map(lambda x: x - int(x) if x >= 1 else -x + int(x) if x < 0 else x, inputs)))\n",
        "        #print(inputs)\n",
        "        targets = targets.view(-1)\n",
        "        #targets = list(map(lambda x: x - int(x) if x >= 0 else -x - int(x)), targets) #no need\n",
        "        return self.actual_loss_func(inputs.to(device), targets)"
      ],
      "metadata": {
        "id": "tGS3jdqwJH2l"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real = torch.full((Loaded.size,), 1.0, dtype=torch.float, device=device)"
      ],
      "metadata": {
        "id": "ycdCj8htbPWT"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6jj3Pj-bcpV",
        "outputId": "5dfd7218-0d60-4931-e908-cf5f52c3c180"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ML = MoleculeLoss()\n",
        "#ML = nn.BCELoss()"
      ],
      "metadata": {
        "id": "LwyiVvnxbdOA"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ttsx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twX57dqG_qJL",
        "outputId": "a659e646-05f9-4469-dc11-09f376154182"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5139, 0.4862, 0.4851, 0.5110, 0.5147, 0.4811, 0.4811, 0.4811, 0.4811,\n",
              "        0.4811, 0.4811, 0.4811, 0.4811, 0.4811], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratiod = ML(ttsx, real, device=device)"
      ],
      "metadata": {
        "id": "u1OaHdxHbgki"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Loss: {ratiod:.9f}\")"
      ],
      "metadata": {
        "id": "m58pni_ybl-U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4daeba0-40b3-497e-f10b-b27a7226cb88"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.716498375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIJ5O-f5rqLd"
      },
      "source": [
        "# Putting it all together / training\n",
        "### Very Incomplete\n",
        "@Task Deadline: Wednesday    \n",
        "@Update: Fix Training Loop   \n",
        "@TODO: Specify `batch_size`  \n",
        "@TODO: Include postprocessing in loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "D5j-6lIMRW_g"
      },
      "outputs": [],
      "source": [
        "discriminator = Discriminator(data_shape=(1, 4)).to(device)\n",
        "generator = QuantumGenerator().to(device)\n",
        "processor = Processing(nocb=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "ckRMx_FFhtJJ"
      },
      "outputs": [],
      "source": [
        "criterion = MoleculeLoss()\n",
        "\n",
        "# Optimisers\n",
        "optD = optim.SGD(discriminator.parameters(), lr=lrD)\n",
        "optG = optim.SGD(generator.parameters(), lr=lrG)\n",
        "\n",
        "batch_size = Loaded.size\n",
        "\n",
        "real_labels = torch.full((batch_size,), 1.0, dtype=torch.float, device=device)\n",
        "fake_labels = torch.full((batch_size,), 0.0, dtype=torch.float, device=device)\n",
        "\n",
        "# Fixed noise allows us to visually track the generated MOLECULES throughout training\n",
        "fixed_noise = torch.rand(n_qubits, device=device) * math.pi / 2\n",
        "\n",
        "# Iteration counter\n",
        "counter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BOvMk93Rrpc",
        "outputId": "1ac4618b-747d-4613-f63c-cd2af168242f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MoleculeLoss(\n",
              "  (actual_loss_func): BCELoss()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "criterion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_DbJkwDhyMc",
        "outputId": "8eec232b-b92f-4bd1-d72d-5d552c71ab6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "real_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VEGlHHeh1YG",
        "outputId": "d2d524b5-4f61-4fab-b988-17a7d7b301ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "fake_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "-eIZOCkA49Cp"
      },
      "outputs": [],
      "source": [
        "ratom_dict = {1: \"H\", 2: \"C\", 3 : \"O\", 4: \"N\"}\n",
        "def look_good(data) -> None:\n",
        "    for d in data:\n",
        "        print(f\"Atom={ratom_dict[int(d[0])]},\\tx={d[1]:.9f},\\ty={d[2]:.9f},\\tz={d[3]:.9f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "41l3v1AJYYCj"
      },
      "outputs": [],
      "source": [
        "num_iter = 23\n",
        "counter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "yJKyyoXgp2BS",
        "outputId": "54b0fc66-3fe9-422e-d12d-35a9ee88c3c1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-a7d2b71c0dfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Training the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0moutD_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.view(-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0moutD_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.view(-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#outD_fake = [abs(breh) - abs(int(breh)) for breh in outD_fake]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-76810f0f09ec>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, mol)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#print(len(mol), len(mol[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mvalidity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalidity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (14x4 and 56x8)"
          ]
        }
      ],
      "source": [
        "for i in range(len(Loaded)):\n",
        "    data = Loaded.df[i]\n",
        "    data = torch.tensor(data, dtype=torch.double, requires_grad=True)\n",
        "    # Data for training the discriminator\n",
        "    real_data = data.to(device)\n",
        "\n",
        "    # Noise follwing a uniform distribution in range [0,pi/2)\n",
        "    #noise = torch.rand(n_qubits.size, device=device) * math.pi / 2\n",
        "    fake_data = generator(fixed_noise)\n",
        "    fake_data = [processor.atomsAndCoordinates(out) for out in fake_data]\n",
        "    fake_data = torch.tensor(fake_data, requires_grad=True).to(device)\n",
        "\n",
        "    # Training the discriminator\n",
        "    discriminator.zero_grad()\n",
        "    outD_real = discriminator(real_data)#.view(-1)\n",
        "    outD_fake = discriminator(fake_data)#.view(-1)\n",
        "    #outD_fake = [abs(breh) - abs(int(breh)) for breh in outD_fake]\n",
        "    #outD_real = [abs(breh) - abs(int(breh)) for breh in outD_real]\n",
        "\n",
        "    errD_real = criterion(torch.tensor(outD_real, requires_grad=True).to(device), real_labels)\n",
        "    errD_fake = criterion(torch.tensor(outD_fake, requires_grad=True).to(device), fake_labels)\n",
        "\n",
        "    #for j in range(5):\n",
        "        #print(f\"outD_real is {torch.tensor([outD_real[j]])}\\n outD_fake is {torch.tensor([outD_fake[j]])}\")\n",
        "    #    errD_real += criterion(torch.tensor([abs(outD_real[j])]).to(device), real_labels)\n",
        "    #    errD_fake += criterion(torch.tensor([abs(outD_fake[j])]).to(device), fake_labels)\n",
        "\n",
        "    errD_real = torch.tensor(errD_real, requires_grad=True).to(device)\n",
        "    errD_fake = torch.tensor(errD_fake, requires_grad=True).to(device)\n",
        "\n",
        "    # Propagate gradients\n",
        "    errD_real.backward()\n",
        "    errD_fake.backward()\n",
        "\n",
        "    errD = errD_real + errD_fake\n",
        "    optD.step()\n",
        "\n",
        "    # Training the generator\n",
        "    generator.zero_grad()\n",
        "    outD_fake = discriminator(fake_data).view(-1)\n",
        "    #outD_fake = [abs(breh) - abs(int(breh)) for breh in outD_fake]\n",
        "    errG = criterion(torch.tensor(outD_fake).to(device), real_labels)\n",
        "    errG = torch.tensor(errG, requires_grad=True).to(device)\n",
        "    errG.backward()\n",
        "    optG.step()\n",
        "\n",
        "    counter += 1\n",
        "\n",
        "    # Show loss values\n",
        "    if counter % 3 == 0:\n",
        "        print(f'Iteration: {counter}, Discriminator Loss: {errD:0.6f}, Generator Loss: {errG:0.6f}')\n",
        "        print(f\"Generated Molecules:\")\n",
        "        look_good(fake_data)\n",
        "        print()\n",
        "\n",
        "    if counter == num_iter:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = int(input().strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqyup1gyHjQb",
        "outputId": "f0948e44-4e5b-4d3b-b83f-ee0c4664fa95"
      },
      "execution_count": 88,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"We will need {q*processor.num_of_total_bits} qubits to make a length {q} molecule\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYDje8PCFrrA",
        "outputId": "ed294bee-0ae3-48d8-e0f1-d130a10cca38"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We will need 100 qubits to make a length 5 molecule\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "yrwEnBIarR8X",
        "SvnFPDmqrXOo",
        "VMeo8twZrh-3",
        "8EiBZIlEnx7F",
        "H6mck8j8rcb0",
        "B3ITXaz7ZweF"
      ],
      "name": "April Fools Joke.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}